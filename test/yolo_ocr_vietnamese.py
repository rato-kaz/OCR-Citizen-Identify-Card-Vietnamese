import os
import cv2
import json
import time
import numpy as np
from ultralytics import YOLO
from vietocr.tool.predictor import Predictor
from vietocr.tool.config import Cfg
from PIL import Image

def setup_models():
    """Kh·ªüi t·∫°o YOLO v√† VietOCR models v·ªõi c·∫•u h√¨nh t·ªëi ∆∞u cho ti·∫øng Vi·ªát"""
    print("üöÄ Kh·ªüi t·∫°o models...")
    
    # Kh·ªüi t·∫°o YOLO
    yolo_model_path = 'models/Text_Detection/YOLO/ID_CARD_2.pt'
    if not os.path.exists(yolo_model_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y YOLO model: {yolo_model_path}")
        return None, None
    
    try:
        yolo_model = YOLO(yolo_model_path)
        print("‚úÖ YOLO model loaded successfully")
    except Exception as e:
        print(f"‚ùå L·ªói khi load YOLO model: {e}")
        return None, None
    
    # Kh·ªüi t·∫°o VietOCR v·ªõi c·∫•u h√¨nh t·ªëi ∆∞u cho ti·∫øng Vi·ªát
    try:
        model_name = 'vgg_transformer'  # ho·∫∑c 'vgg_seq2seq'
        config = Cfg.load_config_from_name(model_name)
        config['weights'] = f'models/Text_Recognition/Vietocr/{model_name}.pth'
        config['device'] = 'cuda:0'  # ho·∫∑c 'cpu'
        ocr = Predictor(config)
        print("‚úÖ VietOCR Vietnamese model loaded successfully")
    except Exception as e:
        print(f"‚ùå L·ªói khi load VietOCR model: {e}")
        return None, None
    
    return yolo_model, ocr

def detect_text_regions(yolo_model, image_path):
    """YOLO detect c√°c v√πng text - ch·ªâ l·∫•y c√°c v√πng c√≥ text"""
    print(f"üîç YOLO ƒëang detect text regions...")
    start_time = time.time()
    
    # Ch·ªâ OCR c√°c v√πng c√≥ text th√¥ng tin
    text_labels = ["dob", "gender", "id", "name", "nationality", "current_place1", "current_place2", "expire_date", "issue_date", "origin_place1", "origin_place2", "personal_identifi"]
    text_class_ids = []
    
    # L·∫•y class names t·ª´ model
    class_names = {}
    if hasattr(yolo_model, 'names'):
        class_names = yolo_model.names
        for class_id, class_name in class_names.items():
            if class_name in text_labels:
                text_class_ids.append(int(class_id))
    
    print(f"üìù Ch·ªâ OCR c√°c v√πng: {text_labels}")
    print(f"üî¢ Class IDs c·∫ßn OCR: {text_class_ids}")
    
    # Hi·ªÉn th·ªã mapping ID -> t√™n class
    if class_names:
        print(f"üìã Mapping Class IDs -> Names:")
        for class_id in text_class_ids:
            class_name = class_names.get(class_id, f"class_{class_id}")
            print(f"  - ID {class_id}: {class_name}")
    
    try:
        results = yolo_model(image_path)
        detection_time = time.time() - start_time
        
        text_regions = []
        all_regions = []
        
        for result in results:
            if result.boxes is not None:
                boxes = result.boxes.xyxy.cpu().numpy()
                confidences = result.boxes.conf.cpu().numpy()
                classes = result.boxes.cls.cpu().numpy()
                
                for i, (box, conf, cls) in enumerate(zip(boxes, confidences, classes)):
                    x1, y1, x2, y2 = box.astype(int)
                    class_id = int(cls)
                    class_name = class_names.get(class_id, f"class_{class_id}")
                    
                    region_info = {
                        'id': i + 1,
                        'bbox': [int(x1), int(y1), int(x2), int(y2)],
                        'confidence': float(conf),
                        'class_id': class_id,
                        'class_name': class_name
                    }
                    
                    all_regions.append(region_info)
                    
                    # Ch·ªâ th√™m v√†o text_regions n·∫øu l√† v√πng c√≥ text
                    if class_id in text_class_ids:
                        text_regions.append(region_info)
        
        print(f"‚úÖ YOLO detect {len(all_regions)} regions t·ªïng c·ªông")
        print(f"üìù Ch·ªâ OCR {len(text_regions)} v√πng c√≥ text trong {detection_time:.3f}s")
        return text_regions, detection_time, all_regions
        
    except Exception as e:
        print(f"‚ùå L·ªói YOLO detection: {e}")
        return [], 0, []

def extract_text_from_regions(ocr, image_path, text_regions):
    """VietOCR extract text t·ª´ c√°c v√πng ƒë√£ detect"""
    print(f"üîç VietOCR ƒëang extract text t·ª´ c√°c v√πng ƒë√£ detect...")
    
    start_time = time.time()
    extracted_results = []
    
    # Load ·∫£nh g·ªëc
    image = cv2.imread(image_path)
    if image is None:
        print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
        return [], 0
    
    for region in text_regions:
        x1, y1, x2, y2 = region['bbox']
        cropped_image = image[y1:y2, x1:x2]
        
        # Convert OpenCV image to PIL Image for VietOCR
        cropped_pil = Image.fromarray(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))
        
        try:
            text = ocr.predict(cropped_pil)
            extracted_results.append({
                'bbox': region['bbox'],
                'extracted_text': text,
                'yolo_confidence': region['confidence'],
                'ocr_confidence': 1.0,  # VietOCR kh√¥ng tr·∫£ v·ªÅ confidence
                'class_id': region['class_id'],
                'class_name': region['class_name']
            })
        except Exception as e:
            print(f"‚ö†Ô∏è  L·ªói OCR cho region {region['id']} ({region['class_name']}): {e}")
            extracted_results.append({
                'bbox': region['bbox'],
                'extracted_text': '',
                'yolo_confidence': region['confidence'],
                'ocr_confidence': 0.0,
                'class_id': region['class_id'],
                'class_name': region['class_name']
            })
    
    extraction_time = time.time() - start_time
    print(f"‚úÖ VietOCR extract {len(extracted_results)} text trong {extraction_time:.3f}s")
    return extracted_results, extraction_time

def save_results(image_path, all_results, detection_time, ocr_time, total_time):
    """L∆∞u k·∫øt qu·∫£ ra file JSON v√† ·∫£nh"""
    try:
        # T·∫°o th∆∞ m·ª•c output
        output_dir = "output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # L∆∞u JSON
        result_data = {
            'image_path': image_path,
            'timing': {
                'detection_time': detection_time,
                'ocr_time': ocr_time,
                'total_time': total_time
            },
            'total_regions': len(all_results),
            'results': all_results
        }
        
        json_file = os.path.join(output_dir, f"yolo_ocr_vietnamese_{os.path.basename(image_path)}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        print(f"üíæ ƒê√£ l∆∞u k·∫øt qu·∫£ JSON: {json_file}")
        
        # T·∫°o ·∫£nh k·∫øt qu·∫£
        create_result_image(image_path, all_results, output_dir)
        
    except Exception as e:
        print(f"‚ùå L·ªói khi l∆∞u k·∫øt qu·∫£: {e}")

def create_result_image(image_path, results, output_dir):
    """T·∫°o ·∫£nh k·∫øt qu·∫£ v·ªõi bounding box v√† text"""
    try:
        image = cv2.imread(image_path)
        if image is None:
            return
        
        colors = [
            (0, 255, 0),    # Xanh l√°
            (255, 0, 0),    # Xanh d∆∞∆°ng
            (0, 0, 255),    # ƒê·ªè
            (255, 255, 0),  # V√†ng
            (255, 0, 255),  # Magenta
            (0, 255, 255),  # Cyan
        ]
        
        for result in results:
            bbox = result['bbox']
            text = result['extracted_text']
            yolo_conf = result['yolo_confidence']
            ocr_conf = result['ocr_confidence']
            cls_id = result['class_id']
            cls_name = result['class_name']
            
            x1, y1, x2, y2 = bbox
            color = colors[cls_id % len(colors)]
            
            # V·∫Ω bounding box
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            
            # V·∫Ω label v·ªõi t√™n class
            label = f"{cls_name} (Y:{yolo_conf:.2f})"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
            
            # Background cho text
            cv2.rectangle(image, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), color, -1)
            
            # Text
            cv2.putText(image, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # V·∫Ω extracted text b√™n d∆∞·ªõi
            if text:
                text_label = f"'{text[:30]}{'...' if len(text) > 30 else ''}'"
                text_y = y2 + 20
                cv2.putText(image, text_label, (x1, text_y), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        
        # L∆∞u ·∫£nh
        output_path = os.path.join(output_dir, f"yolo_ocr_vietnamese_{os.path.basename(image_path)}")
        cv2.imwrite(output_path, image)
        print(f"üñºÔ∏è  ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: {output_path}")
        
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫°o ·∫£nh k·∫øt qu·∫£: {e}")

def process_image(yolo_model, ocr, image_path):
    """X·ª≠ l√Ω m·ªôt ·∫£nh v·ªõi YOLO + VietOCR pipeline"""
    print(f"\n{'='*60}")
    print(f"üñºÔ∏è  X·ª≠ l√Ω ·∫£nh: {image_path}")
    print(f"{'='*60}")
    
    total_start_time = time.time()
    
    # B∆∞·ªõc 1: YOLO Detection
    text_regions, detection_time, all_regions = detect_text_regions(yolo_model, image_path)
    
    if not text_regions:
        print("‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y v√πng text n√†o c·∫ßn OCR")
        return None
    
    # B∆∞·ªõc 2: VietOCR Text Extraction
    extracted_results, ocr_time = extract_text_from_regions(ocr, image_path, text_regions)
    
    total_time = time.time() - total_start_time
    
    # B∆∞·ªõc 3: L∆∞u k·∫øt qu·∫£
    save_results(image_path, extracted_results, detection_time, ocr_time, total_time)
    
    # In th·ªëng k√™
    print(f"\nüìä TH·ªêNG K√ä:")
    print(f"  üîç YOLO Detection: {detection_time:.3f}s")
    print(f"  üìù VietOCR: {ocr_time:.3f}s")
    print(f"  ‚è±Ô∏è  Total Time: {total_time:.3f}s")
    print(f"  üìç T·ªïng regions detected: {len(all_regions)}")
    print(f"  üìù Regions c·∫ßn OCR: {len(text_regions)}")
    print(f"  üìÑ Text extracted: {len(extracted_results)}")
    
    # In chi ti·∫øt c√°c v√πng ƒë√£ OCR
    print(f"\nüìã CHI TI·∫æT C√ÅC V√ôNG ƒê√É OCR:")
    for result in extracted_results:
        print(f"  - {result['class_name']}: '{result['extracted_text']}' (conf: {result['yolo_confidence']:.2f})")
    
    return extracted_results

def main():
    """H√†m ch√≠nh"""
    print("üöÄ YOLO + VietOCR Vietnamese Pipeline")
    print("=" * 60)
    
    # Kh·ªüi t·∫°o models
    yolo_model, ocr = setup_models()
    if yolo_model is None or ocr is None:
        return
    
    # Danh s√°ch ·∫£nh test
    test_images = [
        "img527.jpg",
        "49.jpg"
    ]
    
    all_results = {}
    total_processing_time = 0
    
    for image_path in test_images:
        if not os.path.exists(image_path):
            print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y ·∫£nh: {image_path}")
            continue
        
        start_time = time.time()
        results = process_image(yolo_model, ocr, image_path)
        processing_time = time.time() - start_time
        
        if results:
            all_results[image_path] = {
                'results': results,
                'processing_time': processing_time
            }
            total_processing_time += processing_time
    
    # T·ªïng k·∫øt
    print(f"\n{'='*60}")
    print("üìä T·ªîNG K·∫æT")
    print(f"{'='*60}")
    print(f"üñºÔ∏è  S·ªë ·∫£nh ƒë√£ x·ª≠ l√Ω: {len(all_results)}")
    print(f"‚è±Ô∏è  T·ªïng th·ªùi gian x·ª≠ l√Ω: {total_processing_time:.3f}s")
    print(f"üìÅ K·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c 'output/'")
    print("‚úÖ Pipeline ho√†n th√†nh!")

if __name__ == "__main__":
    main()
