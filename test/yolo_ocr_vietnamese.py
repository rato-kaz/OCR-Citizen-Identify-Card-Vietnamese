import os
import cv2
import json
import time
import numpy as np
from ultralytics import YOLO
from vietocr.tool.predictor import Predictor
from vietocr.tool.config import Cfg
from PIL import Image

def setup_models():
    """Khá»Ÿi táº¡o YOLO vÃ  VietOCR models vá»›i cáº¥u hÃ¬nh tá»‘i Æ°u cho tiáº¿ng Viá»‡t"""
    print("ğŸš€ Khá»Ÿi táº¡o models...")
    
    # Khá»Ÿi táº¡o YOLO
    yolo_model_path = 'models/Text_Detection/YOLO/ID_CARD_2.pt'
    if not os.path.exists(yolo_model_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y YOLO model: {yolo_model_path}")
        return None, None
    
    try:
        yolo_model = YOLO(yolo_model_path)
        print("âœ… YOLO model loaded successfully")
    except Exception as e:
        print(f"âŒ Lá»—i khi load YOLO model: {e}")
        return None, None
    
    # Khá»Ÿi táº¡o VietOCR vá»›i cáº¥u hÃ¬nh tá»‘i Æ°u cho tiáº¿ng Viá»‡t
    try:
        model_name = 'vgg_transformer'  # hoáº·c 'vgg_seq2seq'
        config = Cfg.load_config_from_name(model_name)
        config['weights'] = f'models/Text_Recognition/Vietocr/{model_name}.pth'
        config['device'] = 'cuda:0'  # hoáº·c 'cpu'
        ocr = Predictor(config)
        print("âœ… VietOCR Vietnamese model loaded successfully")
    except Exception as e:
        print(f"âŒ Lá»—i khi load VietOCR model: {e}")
        return None, None
    
    return yolo_model, ocr

def detect_text_regions(yolo_model, image_path):
    """YOLO detect cÃ¡c vÃ¹ng text - chá»‰ láº¥y cÃ¡c vÃ¹ng cÃ³ text"""
    print(f"ğŸ” YOLO Ä‘ang detect text regions...")
    start_time = time.time()
    
    # Chá»‰ OCR cÃ¡c vÃ¹ng cÃ³ text thÃ´ng tin
    text_labels = ["dob", "gender", "id", "name", "nationality", "current_place1", "current_place2", "expire_date", "issue_date", "origin_place1", "origin_place2", "personal_identifi"]
    text_class_ids = []
    
    # Láº¥y class names tá»« model
    class_names = {}
    if hasattr(yolo_model, 'names'):
        class_names = yolo_model.names
        for class_id, class_name in class_names.items():
            if class_name in text_labels:
                text_class_ids.append(int(class_id))
    
    print(f"ğŸ“ Chá»‰ OCR cÃ¡c vÃ¹ng: {text_labels}")
    print(f"ğŸ”¢ Class IDs cáº§n OCR: {text_class_ids}")
    
    # Hiá»ƒn thá»‹ mapping ID -> tÃªn class
    if class_names:
        print(f"ğŸ“‹ Mapping Class IDs -> Names:")
        for class_id in text_class_ids:
            class_name = class_names.get(class_id, f"class_{class_id}")
            print(f"  - ID {class_id}: {class_name}")
    
    try:
        results = yolo_model(image_path)
        detection_time = time.time() - start_time
        
        text_regions = []
        all_regions = []
        
        for result in results:
            if result.boxes is not None:
                boxes = result.boxes.xyxy.cpu().numpy()
                confidences = result.boxes.conf.cpu().numpy()
                classes = result.boxes.cls.cpu().numpy()
                
                for i, (box, conf, cls) in enumerate(zip(boxes, confidences, classes)):
                    x1, y1, x2, y2 = box.astype(int)
                    class_id = int(cls)
                    class_name = class_names.get(class_id, f"class_{class_id}")
                    
                    region_info = {
                        'id': i + 1,
                        'bbox': [int(x1), int(y1), int(x2), int(y2)],
                        'confidence': float(conf),
                        'class_id': class_id,
                        'class_name': class_name
                    }
                    
                    all_regions.append(region_info)
                    
                    # Chá»‰ thÃªm vÃ o text_regions náº¿u lÃ  vÃ¹ng cÃ³ text
                    if class_id in text_class_ids:
                        text_regions.append(region_info)
        
        print(f"âœ… YOLO detect {len(all_regions)} regions tá»•ng cá»™ng")
        print(f"ğŸ“ Chá»‰ OCR {len(text_regions)} vÃ¹ng cÃ³ text trong {detection_time:.3f}s")
        return text_regions, detection_time, all_regions
        
    except Exception as e:
        print(f"âŒ Lá»—i YOLO detection: {e}")
        return [], 0, []

def extract_text_from_regions(ocr, image_path, text_regions):
    """VietOCR extract text tá»« cÃ¡c vÃ¹ng Ä‘Ã£ detect"""
    print(f"ğŸ” VietOCR Ä‘ang extract text tá»« cÃ¡c vÃ¹ng Ä‘Ã£ detect...")
    
    start_time = time.time()
    extracted_results = []
    
    # Load áº£nh gá»‘c
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ KhÃ´ng thá»ƒ Ä‘á»c áº£nh: {image_path}")
        return [], 0
    
    for region in text_regions:
        x1, y1, x2, y2 = region['bbox']
        cropped_image = image[y1:y2, x1:x2]
        
        # Convert OpenCV image to PIL Image for VietOCR
        cropped_pil = Image.fromarray(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))
        
        try:
            text = ocr.predict(cropped_pil)
            extracted_results.append({
                'bbox': region['bbox'],
                'extracted_text': text,
                'yolo_confidence': region['confidence'],
                'ocr_confidence': 1.0,  # VietOCR khÃ´ng tráº£ vá» confidence
                'class_id': region['class_id'],
                'class_name': region['class_name']
            })
        except Exception as e:
            print(f"âš ï¸  Lá»—i OCR cho region {region['id']} ({region['class_name']}): {e}")
            extracted_results.append({
                'bbox': region['bbox'],
                'extracted_text': '',
                'yolo_confidence': region['confidence'],
                'ocr_confidence': 0.0,
                'class_id': region['class_id'],
                'class_name': region['class_name']
            })
    
    extraction_time = time.time() - start_time
    print(f"âœ… VietOCR extract {len(extracted_results)} text trong {extraction_time:.3f}s")
    return extracted_results, extraction_time

def save_results(image_path, all_results, detection_time, ocr_time, total_time):
    """LÆ°u káº¿t quáº£ ra file JSON vÃ  áº£nh"""
    try:
        # Táº¡o thÆ° má»¥c output
        output_dir = "output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # LÆ°u JSON
        result_data = {
            'image_path': image_path,
            'timing': {
                'detection_time': detection_time,
                'ocr_time': ocr_time,
                'total_time': total_time
            },
            'total_regions': len(all_results),
            'results': all_results
        }
        
        json_file = os.path.join(output_dir, f"yolo_ocr_vietnamese_{os.path.basename(image_path)}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ JSON: {json_file}")
        
        # Táº¡o áº£nh káº¿t quáº£
        create_result_image(image_path, all_results, output_dir)
        
    except Exception as e:
        print(f"âŒ Lá»—i khi lÆ°u káº¿t quáº£: {e}")

def create_result_image(image_path, results, output_dir):
    """Táº¡o áº£nh káº¿t quáº£ vá»›i bounding box vÃ  text"""
    try:
        image = cv2.imread(image_path)
        if image is None:
            return
        
        colors = [
            (0, 255, 0),    # Xanh lÃ¡
            (255, 0, 0),    # Xanh dÆ°Æ¡ng
            (0, 0, 255),    # Äá»
            (255, 255, 0),  # VÃ ng
            (255, 0, 255),  # Magenta
            (0, 255, 255),  # Cyan
        ]
        
        for result in results:
            bbox = result['bbox']
            text = result['extracted_text']
            yolo_conf = result['yolo_confidence']
            ocr_conf = result['ocr_confidence']
            cls_id = result['class_id']
            cls_name = result['class_name']
            
            x1, y1, x2, y2 = bbox
            color = colors[cls_id % len(colors)]
            
            # Váº½ bounding box
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            
            # Váº½ label vá»›i tÃªn class
            label = f"{cls_name} (Y:{yolo_conf:.2f})"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
            
            # Background cho text
            cv2.rectangle(image, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), color, -1)
            
            # Text
            cv2.putText(image, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # Váº½ extracted text bÃªn dÆ°á»›i
            if text:
                text_label = f"'{text[:30]}{'...' if len(text) > 30 else ''}'"
                text_y = y2 + 20
                cv2.putText(image, text_label, (x1, text_y), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        
        # LÆ°u áº£nh
        output_path = os.path.join(output_dir, f"yolo_ocr_vietnamese_{os.path.basename(image_path)}")
        cv2.imwrite(output_path, image)
        print(f"ğŸ–¼ï¸  ÄÃ£ lÆ°u áº£nh káº¿t quáº£: {output_path}")
        
    except Exception as e:
        print(f"âŒ Lá»—i khi táº¡o áº£nh káº¿t quáº£: {e}")

def process_image(yolo_model, ocr, image_path):
    """Xá»­ lÃ½ má»™t áº£nh vá»›i YOLO + VietOCR pipeline"""
    print(f"\n{'='*60}")
    print(f"ğŸ–¼ï¸  Xá»­ lÃ½ áº£nh: {image_path}")
    print(f"{'='*60}")
    
    total_start_time = time.time()
    
    # BÆ°á»›c 1: YOLO Detection
    text_regions, detection_time, all_regions = detect_text_regions(yolo_model, image_path)
    
    if not text_regions:
        print("âš ï¸  KhÃ´ng tÃ¬m tháº¥y vÃ¹ng text nÃ o cáº§n OCR")
        return None
    
    # BÆ°á»›c 2: VietOCR Text Extraction
    extracted_results, ocr_time = extract_text_from_regions(ocr, image_path, text_regions)
    
    total_time = time.time() - total_start_time
    
    # BÆ°á»›c 3: LÆ°u káº¿t quáº£
    save_results(image_path, extracted_results, detection_time, ocr_time, total_time)
    
    # In thá»‘ng kÃª
    print(f"\nğŸ“Š THá»NG KÃŠ:")
    print(f"  ğŸ” YOLO Detection: {detection_time:.3f}s")
    print(f"  ğŸ“ VietOCR: {ocr_time:.3f}s")
    print(f"  â±ï¸  Total Time: {total_time:.3f}s")
    print(f"  ğŸ“ Tá»•ng regions detected: {len(all_regions)}")
    print(f"  ğŸ“ Regions cáº§n OCR: {len(text_regions)}")
    print(f"  ğŸ“„ Text extracted: {len(extracted_results)}")
    
    # In chi tiáº¿t cÃ¡c vÃ¹ng Ä‘Ã£ OCR
    print(f"\nğŸ“‹ CHI TIáº¾T CÃC VÃ™NG ÄÃƒ OCR:")
    for result in extracted_results:
        print(f"  - {result['class_name']}: '{result['extracted_text']}' (conf: {result['yolo_confidence']:.2f})")
    
    return extracted_results

def main():
    """HÃ m chÃ­nh"""
    print("ğŸš€ YOLO + VietOCR Vietnamese Pipeline")
    print("=" * 60)
    
    # Khá»Ÿi táº¡o models
    yolo_model, ocr = setup_models()
    if yolo_model is None or ocr is None:
        return
    
    # Danh sÃ¡ch áº£nh test
    test_images = [
        "img527.jpg",
        "49.jpg"
    ]
    
    all_results = {}
    total_processing_time = 0
    
    for image_path in test_images:
        if not os.path.exists(image_path):
            print(f"âš ï¸  KhÃ´ng tÃ¬m tháº¥y áº£nh: {image_path}")
            continue
        
        start_time = time.time()
        results = process_image(yolo_model, ocr, image_path)
        processing_time = time.time() - start_time
        
        if results:
            all_results[image_path] = {
                'results': results,
                'processing_time': processing_time
            }
            total_processing_time += processing_time
    
    # Tá»•ng káº¿t
    print(f"\n{'='*60}")
    print("ğŸ“Š Tá»”NG Káº¾T")
    print(f"{'='*60}")
    print(f"ğŸ–¼ï¸  Sá»‘ áº£nh Ä‘Ã£ xá»­ lÃ½: {len(all_results)}")
    print(f"â±ï¸  Tá»•ng thá»i gian xá»­ lÃ½: {total_processing_time:.3f}s")
    print(f"ğŸ“ Káº¿t quáº£ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c 'output/'")
    print("âœ… Pipeline hoÃ n thÃ nh!")

if __name__ == "__main__":
    main()
